---
layout: default
---


<div style="padding:56.25% 0 0 0;position:relative;"><iframe src="https://player.vimeo.com/video/906586131?badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" style="position:absolute;top:0;left:0;width:100%;height:100%;" title="Bremers et al. (2023) The BAD Dataset"></iframe></div><script src="https://player.vimeo.com/api/player.js"></script>


# A dataset of bystander facial reactions to human and robot failures.

We introduce the Bystander Affect Detection dataset -- a dataset of videos of bystander reactions to videos of failures. This dataset includes 2452 human reactions to failure, collected in contexts that approximate "in-the-wild" data collection -- including natural variances in webcam quality, lighting, and background.

Our video dataset may be requested for use in related research projects. As the dataset contains facial video data of our participants, access can be requested along with the presentation of a research protocol or data use agreement that protects participants.  

This project is part of a collaborative research effort between Cornell Tech (PI: Associate Professor Wendy Ju) and Accenture Labs.

Read our paper here: [link](https://ieeexplore.ieee.org/document/10342442).

Request access to the BAD dataset by sending a message via the button "Contact Owner" through the Qualitative Data Repository (best accessible through Google Chrome): [link](https://data.qdr.syr.edu/dataset.xhtml?persistentId=doi:10.5064/F6TAWBGS).

## Dataset characteristics 

The BAD Dataset covers:
* 54 globally sampled participants 
* reactions to 46 stimulus videos 

## Dataset preview

<video src="https://irl-ct.github.io/bad-dataset/assets/video/merge3.mp4" controls="autoplay" style="max-width: 500px;">
</video>

We provide a preview of the dataset by sharing the individual reaction videos to one stimulus video. This sample contains 53 reactions to QID106, which was a [video of a man playing guitar with a part of the guitar breaking off](https://www.jukinmedia.com/licensing/view/922314). The full BAD dataset contains the reaction videos to all 46 stimulus videos.

Download the dataset preview here: [link.](https://irl-ct.github.io/bad-dataset/assets/video/BADdataset_sample_QID106.zip)

## How to cite our work

Our paper has now been published at IROS:

Bremers, A., Parreira, M.T., Fang, X., Friedman, N., Ramirez-Aristizabal, A., Pabst, A., Spasojevic, M., Kuniavsky, M. and Ju, W., 2023. The Bystander Affect Detection (BAD) Dataset for Failure Detection in HRI. 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 11443-11450, doi: 10.1109/IROS55552.2023.10342442.

Our BAD dataset can be cited using its Qualitative Data Repository citation:

Bremers, Alexandra; Fang, Xuanyu; Friedman, Natalie; Ju, Wendy. 2023. "Data for: The Bystander Affect Detection (BAD) Dataset for Failure Detection in HRI". Qualitative Data Repository. https://doi.org/10.5064/F6TAWBGS. QDR Main Collection. V1

For questions, please contact us! E-mail Alexandra Bremers: awb227@cornell.edu

